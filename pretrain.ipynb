{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "184f35fb-48e0-4ac3-a030-c6afcd3c1e93",
   "metadata": {},
   "source": [
    "pip3 install scipy==1.13.1 && \\\r\n",
    "pip3 install -U scikit-learn && \\\r\n",
    "pip3 install scanpy==1.10.3 && \\\r\n",
    "pip3 install anndata==0.10.5.post1 && \\\r\n",
    "pip3 install einops==0.8.0 && \\\r\n",
    "pip3 install local-attention==1.9.14 && \\\r\n",
    "pip3 install gdown && \\\r\n",
    "pip3 install memory-profiler && \\\r\n",
    "pip3 installmega.py\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70d17f9a-534d-42f3-b847-474f66e58f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import argparse\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "from functools import reduce\t\t\t\t\t\t\t\t\t\t\t\t \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import scipy    \n",
    "import sklearn \n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "\n",
    "import utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87b8e0d9-da76-4f03-9e6c-74605dcf3b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/local_attention/rotary.py:33: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled = False)\n",
      "/usr/local/lib/python3.10/site-packages/local_attention/rotary.py:55: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled = False)\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path('performer_pytorch')\n",
    "data_dir.mkdir(exist_ok=True)  \n",
    "\n",
    "from performer_pytorch.performer_pytorch import PerformerLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d0bac1c-4edf-4283-8644-28fc1c483163",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'panglao_human.h5ad'\n",
    "data_dir = Path('data')\n",
    "data_dir.mkdir(exist_ok=True)  \n",
    "path_data = data_dir / filename\n",
    "\n",
    "if False: \n",
    "    !gdown https://drive.google.com/uc?id=15biFWDLipYpM9iTGgaPmBhlgjkUu08bz -O {path_data} \n",
    "\n",
    "if False: \n",
    "    from mega import Mega\n",
    "    mega = Mega()\n",
    "    m = mega.login()\n",
    "    file = m.download_url('https://mega.nz/file/thZVlZrC#g7WYLCIXyBSdabju3jpfLUanx_MTaB4rmhV3h1RnFcU', \n",
    "                          dest_filename=path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d684eeb5-d6c3-4b86-8b57-00433184f7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_gen2vec = data_dir / 'gene2vec_16906.npy'\n",
    "\n",
    "if False: \n",
    "    !gdown https://drive.google.com/uc?id=15aCnM4kyTBwe6S39RsqJ8JJnE9Xj-gyi -O {path_gen2vec}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b780ab7-2bc7-4540-a2f4-12a21c9dd91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'anndata._core.anndata.AnnData'>\n",
      "(1357593, 16906)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/anndata/_core/anndata.py:1906: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1BG</th>\n",
       "      <th>A1CF</th>\n",
       "      <th>A2ML1</th>\n",
       "      <th>A2M</th>\n",
       "      <th>A4GALT</th>\n",
       "      <th>A4GNT</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>AACS</th>\n",
       "      <th>AADACL2</th>\n",
       "      <th>AADAC</th>\n",
       "      <th>AADAT</th>\n",
       "      <th>AAGAB</th>\n",
       "      <th>AAK1</th>\n",
       "      <th>AAMDC</th>\n",
       "      <th>AAMP</th>\n",
       "      <th>AANAT</th>\n",
       "      <th>AAR2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>09cbFwH3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.840998</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0AdkBIuA</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028411</td>\n",
       "      <td>0.028411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.626798</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0frx9XJU</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.049059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0NaEBg2H</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.453423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037561</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.388124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0NQlCyEz</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750278</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.016584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0WaPBWQw</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.452006</td>\n",
       "      <td>2.610123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012644</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.919015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.805893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12cCwzii</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.166541</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1iEKkCnT</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.515515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.563018</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1lIceRcL</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.39369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.837606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1MhXbC7E</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.961442</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A1BG  A1CF  A2ML1       A2M  A4GALT  A4GNT      AAAS      AACS  \\\n",
       "09cbFwH3   0.0   0.0    0.0  0.000000     0.0    0.0  0.000000  0.000000   \n",
       "0AdkBIuA   0.0   0.0    0.0  0.000000     0.0    0.0  0.028411  0.028411   \n",
       "0frx9XJU   0.0   0.0    0.0  0.000000     0.0    0.0  0.000000  0.000000   \n",
       "0NaEBg2H   0.0   0.0    0.0  0.453423     0.0    0.0  0.000000  0.000000   \n",
       "0NQlCyEz   0.0   0.0    0.0  0.000000     0.0    0.0  0.000000  0.000000   \n",
       "0WaPBWQw   0.0   0.0    0.0  0.000000     0.0    0.0  2.452006  2.610123   \n",
       "12cCwzii   0.0   0.0    0.0  0.000000     0.0    0.0  0.000000  0.000000   \n",
       "1iEKkCnT   0.0   0.0    0.0  0.515515     0.0    0.0  0.000000  0.000000   \n",
       "1lIceRcL   0.0   0.0    0.0  0.000000     0.0    0.0  0.000000  0.000000   \n",
       "1MhXbC7E   0.0   0.0    0.0  0.000000     0.0    0.0  0.000000  0.000000   \n",
       "\n",
       "          AADACL2  AADAC  AADAT  AAGAB      AAK1    AAMDC      AAMP  AANAT  \\\n",
       "09cbFwH3      0.0    0.0    0.0    0.0  1.840998  0.00000  0.000000    0.0   \n",
       "0AdkBIuA      0.0    0.0    0.0    0.0  1.626798  0.00000  0.000000    0.0   \n",
       "0frx9XJU      0.0    0.0    0.0    0.0  0.000000  0.00000  0.049059    0.0   \n",
       "0NaEBg2H      0.0    0.0    0.0    0.0  0.037561  0.00000  0.000000    0.0   \n",
       "0NQlCyEz      0.0    0.0    0.0    0.0  0.750278  0.00000  0.016584    0.0   \n",
       "0WaPBWQw      0.0    0.0    0.0    0.0  0.012644  0.00000  1.919015    0.0   \n",
       "12cCwzii      0.0    0.0    0.0    0.0  1.166541  0.00000  0.000000    0.0   \n",
       "1iEKkCnT      0.0    0.0    0.0    0.0  3.563018  0.00000  0.000000    0.0   \n",
       "1lIceRcL      0.0    0.0    0.0    0.0  0.000000  1.39369  0.000000    0.0   \n",
       "1MhXbC7E      0.0    0.0    0.0    0.0  1.961442  0.00000  0.000000    0.0   \n",
       "\n",
       "              AAR2  \n",
       "09cbFwH3  0.000000  \n",
       "0AdkBIuA  0.000000  \n",
       "0frx9XJU  0.000000  \n",
       "0NaEBg2H  3.388124  \n",
       "0NQlCyEz  0.000000  \n",
       "0WaPBWQw  0.805893  \n",
       "12cCwzii  0.000000  \n",
       "1iEKkCnT  0.000000  \n",
       "1lIceRcL  2.837606  \n",
       "1MhXbC7E  0.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sc.read_h5ad(path_data)\n",
    "\n",
    "print(type(data))\n",
    "print(data.shape)\n",
    "\n",
    "# Each row corresponds to a cell's gene expression data, and each column corresponds to a specific gene.\n",
    "pd.DataFrame(data[:10, :17].X.toarray(), columns=data[:10, :17].var_names, index=data[:10, :17].obs_names)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72385487-c689-49e5-8296-d1e94ee0b657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1357593, 16906)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(812188, 16906)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "len(set(data.obs_names)), len(set(data.var_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86151b93-9bee-4c72-a09c-9c888b59d000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_genes</th>\n",
       "      <th>n_genes_by_counts</th>\n",
       "      <th>total_counts</th>\n",
       "      <th>total_counts_mt</th>\n",
       "      <th>pct_counts_mt</th>\n",
       "      <th>Batch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>09cbFwH3</th>\n",
       "      <td>2371</td>\n",
       "      <td>2371</td>\n",
       "      <td>689381.0</td>\n",
       "      <td>43521.0</td>\n",
       "      <td>6.313055</td>\n",
       "      <td>SRA275902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0AdkBIuA</th>\n",
       "      <td>2568</td>\n",
       "      <td>2568</td>\n",
       "      <td>601183.0</td>\n",
       "      <td>41842.0</td>\n",
       "      <td>6.959944</td>\n",
       "      <td>SRA275902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0frx9XJU</th>\n",
       "      <td>1570</td>\n",
       "      <td>1570</td>\n",
       "      <td>341170.0</td>\n",
       "      <td>33386.0</td>\n",
       "      <td>9.785737</td>\n",
       "      <td>SRA275902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0NaEBg2H</th>\n",
       "      <td>3141</td>\n",
       "      <td>3141</td>\n",
       "      <td>438603.0</td>\n",
       "      <td>48809.0</td>\n",
       "      <td>11.128287</td>\n",
       "      <td>SRA275902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0NQlCyEz</th>\n",
       "      <td>3289</td>\n",
       "      <td>3289</td>\n",
       "      <td>1020715.0</td>\n",
       "      <td>36329.0</td>\n",
       "      <td>3.559172</td>\n",
       "      <td>SRA275902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTTGTAATATA</th>\n",
       "      <td>794</td>\n",
       "      <td>794</td>\n",
       "      <td>1433.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>6.699232</td>\n",
       "      <td>SRA878024_SRS4660848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTTTCGCGCGG</th>\n",
       "      <td>609</td>\n",
       "      <td>609</td>\n",
       "      <td>988.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>7.186235</td>\n",
       "      <td>SRA878024_SRS4660848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTTTGGAGCCC</th>\n",
       "      <td>983</td>\n",
       "      <td>983</td>\n",
       "      <td>1930.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>5.284974</td>\n",
       "      <td>SRA878024_SRS4660848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTTTTAGCCCC</th>\n",
       "      <td>323</td>\n",
       "      <td>323</td>\n",
       "      <td>426.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.521127</td>\n",
       "      <td>SRA878024_SRS4660848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTTTTTTAGAT</th>\n",
       "      <td>334</td>\n",
       "      <td>334</td>\n",
       "      <td>462.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6.277056</td>\n",
       "      <td>SRA878024_SRS4660848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1357593 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              n_genes  n_genes_by_counts  total_counts  total_counts_mt  \\\n",
       "09cbFwH3         2371               2371      689381.0          43521.0   \n",
       "0AdkBIuA         2568               2568      601183.0          41842.0   \n",
       "0frx9XJU         1570               1570      341170.0          33386.0   \n",
       "0NaEBg2H         3141               3141      438603.0          48809.0   \n",
       "0NQlCyEz         3289               3289     1020715.0          36329.0   \n",
       "...               ...                ...           ...              ...   \n",
       "TTTTGTAATATA      794                794        1433.0             96.0   \n",
       "TTTTTCGCGCGG      609                609         988.0             71.0   \n",
       "TTTTTGGAGCCC      983                983        1930.0            102.0   \n",
       "TTTTTTAGCCCC      323                323         426.0             15.0   \n",
       "TTTTTTTTAGAT      334                334         462.0             29.0   \n",
       "\n",
       "              pct_counts_mt                 Batch  \n",
       "09cbFwH3           6.313055             SRA275902  \n",
       "0AdkBIuA           6.959944             SRA275902  \n",
       "0frx9XJU           9.785737             SRA275902  \n",
       "0NaEBg2H          11.128287             SRA275902  \n",
       "0NQlCyEz           3.559172             SRA275902  \n",
       "...                     ...                   ...  \n",
       "TTTTGTAATATA       6.699232  SRA878024_SRS4660848  \n",
       "TTTTTCGCGCGG       7.186235  SRA878024_SRS4660848  \n",
       "TTTTTGGAGCCC       5.284974  SRA878024_SRS4660848  \n",
       "TTTTTTAGCCCC       3.521127  SRA878024_SRS4660848  \n",
       "TTTTTTTTAGAT       6.277056  SRA878024_SRS4660848  \n",
       "\n",
       "[1357593 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599aace4-8389-4571-b7fa-32c7f9009d2a",
   "metadata": {},
   "source": [
    "# Sort torch.distributed, CUDA\n",
    "\n",
    "\n",
    "- pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 --upgrade --force-reinstall\n",
    "- pip3 install fsspec==2023.10.0\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "365e4735-b49b-42ea-9369-75b4cf21879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.distributed as dist\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2539088d-5e68-4123-95d9-0728d14d820c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA available: 11.8\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA available:\", torch.version.cuda) \n",
    "print(torch.distributed.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d81a41b0-7b4c-48ea-b689-61c77a8053df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "rank = 0\n",
    "world_size = 1\n",
    "is_master = rank == 0\n",
    "local_rank = 0        # as running on a single GPU \n",
    "\n",
    "os.environ['RANK'] = str(rank)\n",
    "os.environ['WORLD_SIZE'] = str(world_size) \n",
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '12345'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f334950b-d76b-4087-bd02-692563678966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "dist.init_process_group(backend='gloo', init_method='env://')\n",
    "device = torch.device(\"cuda:0\")\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffda932-f9d7-4732-ae78-7ac349711efa",
   "metadata": {},
   "source": [
    "- Padding tokens are used to make all sequences in a batch the same length, ensuring consistency for model training. Ignored during the learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f040dced-7ec3-4d1a-a068-473fa12d2ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2021\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 3\n",
    "GRADIENT_ACCUMULATION = 60\n",
    "LEARNING_RATE = 1e-4\n",
    "SEQ_LEN = 16906 + 1\n",
    "VALIDATE_EVERY = 1\n",
    "CLASS = 5 + 2\n",
    "MASK_PROB = 0.15\n",
    "REPLACE_PROB = 0.9\n",
    "RANDOM_TOKEN_PROB = 0.0\n",
    "MASK_TOKEN_ID = CLASS - 1  # AK: Problem or not?  \n",
    "PAD_TOKEN_ID  = CLASS - 1\n",
    "MASK_IGNORE_TOKEN_IDS = [0]\n",
    "POS_EMBED_USING = True\n",
    "\n",
    "model_name = 'panglao_pretrain'\n",
    "ckpt_dir = './ckpts/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a12801f-987b-4ff1-a77a-3cc61caebf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        rand_start = random.randint(0, self.data.shape[0]-1)\n",
    "        full_seq = self.data[rand_start].toarray()[0]        # Flattening from 2D to 1D. Takes one whole row. \n",
    "        full_seq[full_seq > (CLASS - 2)] = CLASS - 2         # Clip all values in full_seq to be at most CLASS - 2. Normalization. \n",
    "        full_seq = torch.from_numpy(full_seq).long()\n",
    "        full_seq = torch.cat((full_seq, torch.tensor([0]))).to(device)\n",
    "        return full_seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "data_train, data_val = train_test_split(data.X, test_size=0.05,random_state=SEED)\n",
    "\n",
    "train_dataset = SCDataset(data_train)\n",
    "val_dataset = SCDataset(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f305777-acb3-4b7c-b1b4-505c5c7a6220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1289713, 67880)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__len__(), val_dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd0ed8e5-8763-48e9-b7a4-92a90649936a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = DistributedSampler(train_dataset)\n",
    "val_sampler   = utils.SequentialDistributedSampler(val_dataset, batch_size=BATCH_SIZE, world_size=world_size)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cedf46d4-d5bc-465a-9c25-64b6ca025a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PerformerLM(num_tokens = CLASS, dim = 200, depth = 6, max_seq_len = SEQ_LEN,heads = 10,local_attn_heads = 0, \n",
    "                    g2v_position_emb = POS_EMBED_USING)\n",
    "model.to(device)\n",
    "model = DDP(model, device_ids=[local_rank], output_device=local_rank) # DistributedDataParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fab6366a-7217-42aa-b857-1f8c853009ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# learning rate scheduler\n",
    "scheduler = utils.CosineAnnealingWarmupRestarts(optimizer, first_cycle_steps=15, cycle_mult=2, max_lr=LEARNING_RATE,\n",
    "                                                min_lr=1e-6, warmup_steps=5,gamma=0.9)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index = PAD_TOKEN_ID, reduction='mean').to(local_rank)\n",
    "softmax = nn.Softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cf36870-b6c3-4137-beca-c443568337f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the random prob matrix and True means smaller than prob threshold\n",
    "def prob_mask_like(t, prob):\n",
    "    return torch.zeros_like(t).float().uniform_(0, 1) < prob\n",
    "\n",
    "# get the mask matrix which cannot be masked\n",
    "def mask_with_tokens(t, token_ids):\n",
    "    init_no_mask = torch.full_like(t, False, dtype=torch.bool)\n",
    "    mask = reduce(lambda acc, el: acc | (t == el), token_ids, init_no_mask)\n",
    "    return mask\n",
    "\n",
    "def get_mask_subset_with_prob(mask, prob):\n",
    "\n",
    "    batch, seq_len, device = *mask.shape, mask.device\n",
    "    max_masked = math.ceil(prob * seq_len)          # num of mask of a single sequence in average\n",
    "    num_tokens = mask.sum(dim=-1, keepdim=True)     # num of pure tokens of each sequence except special tokens\n",
    "    mask_excess = torch.cat((torch.zeros(0), torch.arange(mask.size(-1)).repeat(mask.size(0)))).reshape(mask.size(0),mask.size(-1)).to(device)\n",
    "    mask_excess = (mask_excess >= (num_tokens * prob).ceil())        # only 15% of pure tokens can be masked\n",
    "    mask_excess = mask_excess[:, :max_masked]       # get difference between 15% of pure tokens and 15% of all tokens\n",
    "    rand = torch.rand((batch, seq_len), device=device).masked_fill(~mask, -1e9)     # rand (0-1) as prob, special token use -1e9\n",
    "    _, sampled_indices = rand.topk(max_masked, dim=-1)      # get index of topk prob to mask\n",
    "    sampled_indices = (sampled_indices + 1).masked_fill_(mask_excess, 0)        # delete difference of mask not pure\n",
    "    new_mask = torch.zeros((batch, seq_len + 1), device=device)     # get (batch, seq_len) shape zero matrix\n",
    "    new_mask.scatter_(-1, sampled_indices, 1)       # set masks in zero matrix as 1\n",
    "    \n",
    "    return new_mask[:, 1:].bool()       # the final mask, True is mask\n",
    "\n",
    "def data_mask(data, mask_prob = MASK_PROB, replace_prob = REPLACE_PROB, num_tokens = None, random_token_prob = RANDOM_TOKEN_PROB,\n",
    "              mask_token_id = MASK_TOKEN_ID, pad_token_id = PAD_TOKEN_ID, mask_ignore_token_ids = MASK_IGNORE_TOKEN_IDS):\n",
    "    \n",
    "    mask_ignore_token_ids = set([*mask_ignore_token_ids, pad_token_id])\n",
    "    # do not mask [pad] tokens, or any other tokens in the tokens designated to be excluded ([cls], [sep])\n",
    "    # also do not include these special tokens in the tokens chosen at random\n",
    "    no_mask = mask_with_tokens(data, mask_ignore_token_ids)    # ignore_token as True, will not be masked later\n",
    "    mask = get_mask_subset_with_prob(~no_mask, mask_prob)      # get the True/False mask matrix\n",
    "    # get mask indices\n",
    "    ## mask_indices = torch.nonzero(mask, as_tuple=True)   # get the index of mask(nonzero value of mask matrix)\n",
    "    # mask input with mask tokens with probability of `replace_prob` (keep tokens the same with probability 1 - replace_prob)\n",
    "    masked_input = data.clone().detach()\n",
    "    # if random token probability > 0 for mlm\n",
    "    if random_token_prob > 0:\n",
    "        assert num_tokens is not None, 'num_tokens keyword must be supplied when instantiating MLM if using random token replacement'\n",
    "        random_token_prob = prob_mask_like(data, random_token_prob)       # get the mask matrix of random token replace\n",
    "        random_tokens = torch.randint(0, num_tokens, data.shape, device=data.device)     # generate random token matrix with the same shape as input\n",
    "        random_no_mask = mask_with_tokens(random_tokens, mask_ignore_token_ids)        # not masked matrix for the random token matrix\n",
    "        random_token_prob &= ~random_no_mask        # get the pure mask matrix of random token replace\n",
    "        random_indices = torch.nonzero(random_token_prob, as_tuple=True)        # index of random token replace\n",
    "        masked_input[random_indices] = random_tokens[random_indices]        # replace some tokens by random token\n",
    "    # [mask] input\n",
    "    replace_prob = prob_mask_like(data, replace_prob)     # get the mask matrix of token being masked\n",
    "    masked_input = masked_input.masked_fill(mask * replace_prob, mask_token_id)        # get the data has been masked by mask_token\n",
    "    # mask out any tokens to padding tokens that were not originally going to be masked\n",
    "    labels = data.masked_fill(~mask, pad_token_id)        # the label of masked tokens\n",
    "    return masked_input, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd55c5c-3628-416b-97d7-a3dba34e7a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.barrier()\n",
    "for i in range(1, EPOCHS+1):\n",
    "    train_loader.sampler.set_epoch(i)\n",
    "    model.train()\n",
    "    dist.barrier()\n",
    "    running_loss = 0.0\n",
    "    cum_acc = 0.0\n",
    "    for index, data in enumerate(train_loader):\n",
    "        index += 1\n",
    "        data = data.to(device)\n",
    "        \n",
    "        data, labels = data_mask(data)\n",
    "        \n",
    "        # accumulates gradients without synchronization, saving resources\n",
    "        if index % GRADIENT_ACCUMULATION != 0: \n",
    "            with model.no_sync():\n",
    "                logits = model(data)\n",
    "                loss = loss_fn(logits.transpose(1, 2), labels) / GRADIENT_ACCUMULATION\n",
    "                loss.backward()\n",
    "        \n",
    "        # synchronizes gradients, applies updates, and resets for the next accumulation phase\n",
    "        if index % GRADIENT_ACCUMULATION == 0: \n",
    "            logits = model(data)\n",
    "            loss = loss_fn(logits.transpose(1, 2), labels) / GRADIENT_ACCUMULATION\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), int(1e2)) # clip grads to prevent exploding gradients\n",
    "            optimizer.step()                                             # updates the model parameters based on the accumulated gradients\n",
    "            optimizer.zero_grad()                                        # resets the gradients to zero, preparing for the next accumulation\n",
    "        running_loss += loss.item()\n",
    "        final = softmax(logits)[..., 1:-1]\n",
    "        final = final.argmax(dim=-1) + 1\n",
    "        pred_num = (labels != PAD_TOKEN_ID).sum(dim=-1)\n",
    "        correct_num = ((labels != PAD_TOKEN_ID) * (final == labels)).sum(dim=-1)\n",
    "        cum_acc += torch.true_divide(correct_num, pred_num).mean().item()\n",
    "    \n",
    "    epoch_loss = running_loss / index\n",
    "    epoch_acc = 100 * cum_acc / index\n",
    "    epoch_loss = utils.get_reduced(epoch_loss, local_rank, 0, world_size)\n",
    "    epoch_acc  = utils.get_reduced(epoch_acc, local_rank, 0, world_size)\n",
    "    if is_master:\n",
    "        print(f'    ==  Epoch: {i} | Training Loss: {epoch_loss:.6f} | Accuracy: {epoch_acc:6.4f}%  ==')\n",
    "    dist.barrier()\n",
    "    scheduler.step()\n",
    "\n",
    "    if i % VALIDATE_EVERY == 0:\n",
    "        model.eval()\n",
    "        dist.barrier()\n",
    "        running_loss = 0.0\n",
    "        running_error = 0.0\n",
    "        predictions = []\n",
    "        truths = []\n",
    "        with torch.no_grad():\n",
    "            for index, data in enumerate(val_loader):\n",
    "                index += 1\n",
    "                data = data.to(device)\n",
    "                \n",
    "                data, labels = data_mask(data)\n",
    "\n",
    "                logits = model(data)\n",
    "                loss = loss_fn(logits.transpose(1, 2), labels)\n",
    "                running_loss += loss.item()\n",
    "                softmax = nn.Softmax(dim=-1)\n",
    "                final = softmax(logits)[..., 1:-1]\n",
    "                final = final.argmax(dim=-1) + 1\n",
    "                predictions.append(final)\n",
    "                truths.append(labels)\n",
    "            del data, labels, logits, final\n",
    "            # gather\n",
    "            predictions = utils.distributed_concat(torch.cat(predictions, dim=0), len(val_sampler.dataset), world_size)\n",
    "            truths = utils.distributed_concat(torch.cat(truths, dim=0), len(val_sampler.dataset), world_size)\n",
    "            correct_num = ((truths != PAD_TOKEN_ID) * (predictions == truths)).sum(dim=-1)[0].item()\n",
    "            val_num = (truths != PAD_TOKEN_ID).sum(dim=-1)[0].item()\n",
    "            val_loss = running_loss / index\n",
    "            val_loss = utils.get_reduced(val_loss, local_rank, 0, world_size)\n",
    "        if is_master:\n",
    "            val_acc = 100 * correct_num / val_num\n",
    "            print(f'    ==  Epoch: {i} | Validation Loss: {val_loss:.6f} | Accuracy: {val_acc:6.4f}%  ==')\n",
    "    del predictions, truths\n",
    "\n",
    "    if is_master:\n",
    "        utils.save_ckpt(i, model, optimizer, scheduler, epoch_loss, model_name, ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f18827-ecf4-4e53-97b7-e4091374df04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
